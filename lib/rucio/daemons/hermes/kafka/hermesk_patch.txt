--- hermes.py	2025-05-02 14:46:50
+++ hermesk.py	2025-05-02 14:45:41
@@ -48,6 +48,7 @@
 from rucio.core.message import delete_messages, retrieve_messages
 from rucio.core.monitor import MetricManager
 from rucio.daemons.common import run_daemon
+from rucio.daemons.hermes.kafka.kafka_support import setup_kafka, deliver_to_kafka
 
 if TYPE_CHECKING:
     from collections.abc import Iterable, Sequence
@@ -62,7 +63,7 @@
 
 METRICS = MetricManager(module=__name__)
 graceful_stop = threading.Event()
-DAEMON_NAME = "hermes"
+DAEMON_NAME = "hermesk"
 
 RECONNECT_COUNTER = METRICS.counter(
     name="reconnect.{host}",
@@ -577,7 +578,7 @@
         )
 
 
-def hermes(once: bool = False, bulk: int = 1000, sleep_time: int = 10) -> None:
+def hermesk(once: bool = False, bulk: int = 1000, sleep_time: int = 10) -> None:
     """
     Creates a Hermes Worker that can submit messages to different services (InfluXDB, ElasticSearch, ActiveMQ)
     The list of services need to be define in the config service in the hermes section.
@@ -642,6 +643,13 @@
         except Exception as err:
             logger(logging.ERROR, str(err))
 
+    message_filter = None
+    if "kafka" in services_list:
+       try:
+           message_filter = setup_kafka(logger)
+       except Exception as err:
+           logging.exception(err)
+
     worker_number, total_workers, logger = heartbeat_handler.live()
     message_dict = {}
     query_by_service = config_get_bool("hermes", "query_by_service", default=False)
@@ -666,8 +674,8 @@
             logger=logger
         )
 
+    to_delete = []
     if message_dict:
-        to_delete = []
 
         if "influx" in message_dict and influx_endpoint:
             # For influxDB, bulk submission, either everything succeeds or fails
@@ -768,6 +776,24 @@
                         to_delete.append(message)
             except Exception as error:
                 logger(logging.ERROR, "Error sending to ActiveMQ : %s", str(error))
+
+        if "kafka" in message_dict:
+            t_time = time.time()
+            try:
+                messages_sent = deliver_to_kafka(
+                    message_filter=message_filter, messages=message_dict["kafka"]
+                )
+                logger(
+                    logging.INFO,
+                    "%s messages processed by Kafka filter in %s seconds",
+                    len(message_dict["kafka"]),
+                    time.time() - t_time,
+                )
+                for message in message_dict["kafka"]:
+                    if message["id"] in messages_sent:
+                        to_delete.append(message)
+            except Exception as error:
+                logger(logging.ERROR, "Error sending to Kafka : %s", str(error))
 
     logger(logging.INFO, "Deleting %s messages", len(to_delete))
     to_delete = [
@@ -812,7 +838,7 @@
     logging.info("starting hermes threads")
     thread_list = [
         threading.Thread(
-            target=hermes,
+            target=hermesk,
             kwargs={
                 "once": once,
                 "bulk": bulk,
